<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Research Portfolio ‚Äì Ngozi Ihemelandu</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 2rem;
      background-color: #f9f9f9;
      color: #333;
    }
    h1, h2, h3, h4 {
      color: #1a1a1a;
    }
    a {
      color: #1a73e8;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    section {
      margin-bottom: 2rem;
    }
  </style>
</head>
<body>

  <header>
    <h1>Welcome to My Research Portfolio</h1>
  </header>

  <section id="research-statement">
    <h2>Research Statement</h2>

    <h3>üî≠ Past Research</h3>
    <p>
      My past research focused on identifying and recommending best practices for applying statistical inference in the analysis of recommender system evaluation experiments. The goal was to enhance the reliability of performance metrics by addressing key statistical challenges and improving the accuracy of evaluation results.
    </p>

    <h3>üî≠ Current Research</h3>
    <p>
      Currently, I am exploring causal inference techniques to estimate the true causal effects of recommended items on user behavior. This research aims to refine the reliability of performance metrics in recommender systems by better understanding the causal relationships between recommendations and user interactions.
    </p>

    <h3>üî≠ Future Research Vision</h3>
    <p>My future research spans the intersection of <strong>causal inference</strong>, <strong>machine learning</strong>, and <strong>decision-making under uncertainty</strong>, with a focus on:</p>
    <!--
    <h4>üìå Causal Inference in Recommender Systems</h4>
    <ul>
      <li>Understanding direct and indirect effects of recommendations</li>
      <li>Improving evaluation metrics beyond clicks and conversions</li>
      <li>Enhancing trust in algorithmic recommendations through causal metrics</li>
    </ul>

    <h4>üìå Supply Chain Decision-Making Under Uncertainty</h4>
    <ul>
      <li>Modeling decisions under stochastic demand and supply</li>
      <li>Evaluating interventions for procurement, inventory, and logistics</li>
      <li>Enhancing operational robustness using counterfactual reasoning</li>
    </ul>

    <h4>üìå Integrating Machine Learning with Causal Inference</h4>
    <ul>
      <li>Scalable, data-driven causal estimation</li>
      <li>Interpretability in high-dimensional, complex systems</li>
      <li>Applications across personalization, logistics, and operations</li>
    </ul>
    
    <p>üëâ See <a href="https://github.com/nihemelandu/future-research.git" target="_blank">future-research</a> for detailed methodology and project roadmap.</p>
    -->
    <h3>üîç Domain Spotlight: AI-Powered Supply Chain Optimization</h3>
    <p>
      The bane of supply chain performance is variability. Supply chains operate at their best when processes are stable and predictable‚Äîthis ideal state is what we refer to as <strong>supply chain optimization</strong>. It means aligning supply and demand efficiently, minimizing waste, reducing costs, and ensuring timely delivery of goods and services.
    </p>
    <p>
      But achieving this balance is increasingly difficult. Uncertainty is introduced not only through internal fluctuations‚Äîsuch as changing lead times, volatile customer demand, or inconsistent supplier performance‚Äîbut also through exogenous forces like government regulations, natural disasters, geopolitical events, or accidents. While internal variability can be mitigated through process control and forecasting, external disruptions require adaptability, resilience, and real-time responsiveness.
    </p>
    <p>
      Without effective mitigation, these uncertainties lead to overstocking or stockouts, product obsolescence, operational inefficiencies, and ultimately, customer dissatisfaction‚Äîall of which impact a company‚Äôs bottom line. That‚Äôs why modern supply chains must evolve beyond static planning toward <strong>AI-powered optimization</strong>‚Äîsystems that can learn, anticipate, and adapt to maintain operational stability even under uncertainty.
    </p>
  </section>

  <section id="publications">
    <h2>Publications</h2>

    <h3><a href="https://arxiv.org/abs/2109.06424" target="_blank">Statistical Inference: The Missing Piece of RecSys Experiment Reliability Discourse</a></h3>
    <p><em>Discusses how statistical inference is often overlooked in recommender system evaluations and outlines challenges that threaten experimental reliability.</em></p>

    <h3><a href="https://arxiv.org/abs/2305.02461" target="_blank">Inference at Scale: Significance Testing for Large Search and Recommendation Experiments</a></h3>
    <p><em>Explores how significance tests behave in large-scale experiments, emphasizing the need to consider practical effect sizes alongside p-values.</em></p>

    <h3><a href="https://md.ekstrandom.net/pubs/ecir2024-multiple-testing.pdf" target="_blank">Multiple Testing for IR and Recommendation System Experiments</a></h3>
    <p><em>Examines the multiple-comparison problem (MCP) in evaluations involving more than two systems and explores procedures that control the False Discovery Rate (FDR).</em></p>

    <h3><a href="https://arxiv.org/pdf/2309.11723" target="_blank">Candidate Set Sampling for Evaluating Top-N Recommendation</a></h3>
    <p><em>Analyzes how candidate set selection strategies interact with popularity bias and affect the accuracy of evaluation metrics in top-N recommendation tasks.</em></p>
  </section>

  <section>
    <hr />
    <p>Feel free to explore the individual papers for more in-depth discussions of the methodologies and findings. For any questions or further details on my work, feel free to reach out!</p>
  </section>

<footer>
      &copy; Ngozi Ihemelandu ¬∑ <a href="https://nihemelandu.github.io">Back to homepage</a>
</footer>

  </body>
</html>
