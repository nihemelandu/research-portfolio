<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Research Portfolio â€“ Ngozi Ihemelandu</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 2rem;
      background-color: #f9f9f9;
      color: #333;
    }
    h1, h2, h3, h4 {
      color: #1a1a1a;
    }
    a {
      color: #1a73e8;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    section {
      margin-bottom: 2rem;
    }
  </style>
</head>
<body>

  <header>
    <h1>Welcome to My Research Portfolio</h1>
  </header>

  <section id="research-statement">
    <h2>Research Statement</h2>

    <h3>ðŸ”­ Past Research</h3>
    <p>
      My past research focused on identifying and recommending best practices for applying statistical inference in the analysis of recommender system evaluation experiments. The goal was to enhance the reliability of performance metrics by addressing key statistical challenges and improving the accuracy of evaluation results.
    </p>

    <h3>ðŸ”­ Current Research</h3>
    <p>
      Currently, I am exploring causal inference techniques to estimate the true causal effects of recommended items on user behavior. This research aims to refine the reliability of performance metrics in recommender systems by better understanding the causal relationships between recommendations and user interactions.
    </p>

    <h3>ðŸ”­ Future Research Vision</h3>
    <p>My future research spans the intersection of <strong>causal inference</strong>, <strong>machine learning</strong>, and <strong>decision-making under uncertainty</strong>, with a focus on:</p>

    <h4>ðŸ“Œ Causal Inference in Recommender Systems</h4>
    <ul>
      <li>Understanding direct and indirect effects of recommendations</li>
      <li>Improving evaluation metrics beyond clicks and conversions</li>
      <li>Enhancing trust in algorithmic recommendations through causal metrics</li>
    </ul>

    <h4>ðŸ“Œ Supply Chain Decision-Making Under Uncertainty</h4>
    <ul>
      <li>Modeling decisions under stochastic demand and supply</li>
      <li>Evaluating interventions for procurement, inventory, and logistics</li>
      <li>Enhancing operational robustness using counterfactual reasoning</li>
    </ul>

    <h4>ðŸ“Œ Integrating Machine Learning with Causal Inference</h4>
    <ul>
      <li>Scalable, data-driven causal estimation</li>
      <li>Interpretability in high-dimensional, complex systems</li>
      <li>Applications across personalization, logistics, and operations</li>
    </ul>

    <p>ðŸ‘‰ See <a href="https://github.com/nihemelandu/future-research.git" target="_blank">future-research</a> for detailed methodology and project roadmap.</p>
  </section>

  <section id="publications">
    <h2>Publications</h2>

    <h3><a href="https://arxiv.org/abs/2109.06424" target="_blank">Statistical Inference: The Missing Piece of RecSys Experiment Reliability Discourse</a></h3>
    <p><em>Discusses how statistical inference is often overlooked in recommender system evaluations and outlines challenges that threaten experimental reliability.</em></p>

    <h3><a href="https://arxiv.org/abs/2305.02461" target="_blank">Inference at Scale: Significance Testing for Large Search and Recommendation Experiments</a></h3>
    <p><em>Explores how significance tests behave in large-scale experiments, emphasizing the need to consider practical effect sizes alongside p-values.</em></p>

    <h3><a href="https://md.ekstrandom.net/pubs/ecir2024-multiple-testing.pdf" target="_blank">Multiple Testing for IR and Recommendation System Experiments</a></h3>
    <p><em>Examines the multiple-comparison problem (MCP) in evaluations involving more than two systems and explores procedures that control the False Discovery Rate (FDR).</em></p>

    <h3><a href="https://arxiv.org/pdf/2309.11723" target="_blank">Candidate Set Sampling for Evaluating Top-N Recommendation</a></h3>
    <p><em>Analyzes how candidate set selection strategies interact with popularity bias and affect the accuracy of evaluation metrics in top-N recommendation tasks.</em></p>
  </section>

  <section>
    <hr />
    <p>Feel free to explore the individual papers for more in-depth discussions of the methodologies and findings. For any questions or further details on my work, feel free to reach out!</p>
  </section>

<footer>
      &copy; Ngozi Ihemelandu Â· <a href="https://nihemelandu.github.io">Back to homepage</a>
</footer>

  </body>
</html>
